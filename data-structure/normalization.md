# Normalization

[机器学习——标准化/归一化的目的、作用和场景](https://blog.csdn.net/zenghaitao0128/article/details/78361038)
[归一化 （Normalization）、标准化 （Standardization）和中心化/零均值化 （Zero-centered）](https://www.jianshu.com/p/95a8f035c86c)
[特征工程中的「归一化」有什么作用？](https://www.zhihu.com/question/20455227)

原理:

1. 把数据变成`[0, 1]`或者`[-1, 1]`之间的小数。主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速
2. 把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权。归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量

作用:

1. 归一化后加快了梯度下降求最优解的速度
2. 归一化有可能提高精度（如KNN）

![norm](./imgs/norm.jpg)

## 方法

### 最大最小标准化（Min-Max Normalization）

应用场景: 在**不涉及**距离度量、协方差计算、数据不符合正太分布的时候，可以使用第一种方法或其他归一化方法（不包括Z-score方法）。比如图像处理中，将RGB图像转换为灰度图像后将其值限定在[0 255]的范围

### Z-score标准化方法

应用场景: 在分类、聚类算法中，**需要使用**距离来度量相似性的时候、或者使用PCA技术进行降维的时候，Z-score standardization表现更好

### 非线性归一化

## 应用场景说明

1. 概率模型不需要归一化，因为这种模型不关心变量的取值，而是关心变量的分布和变量之间的条件概率
2. SVM、线性回归之类的最优化问题需要归一化，是否归一化主要在于是否关心变量取值
3. 神经网络需要标准化处理，一般变量的取值在-1到1之间，这样做是为了弱化某些变量的值较大而对模型产生影响。一般神经网络中的隐藏层采用tanh激活函数比sigmod激活函数要好些，因为tanh双曲正切函数的取值[-1,1]之间，均值为0
4. 在K近邻算法中，如果不对解释变量进行标准化，那么具有小数量级的解释变量的影响就会微乎其微
